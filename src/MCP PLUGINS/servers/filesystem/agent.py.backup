import asyncio
import json
import os
import sys
import threading
import time
import queue
from typing import Any, Dict, List, Tuple, Optional
import uuid

# Force UTF-8 encoding for Windows console
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')
    sys.stderr.reconfigure(encoding='utf-8')

# Load .env for environment variables
try:
    import dotenv
    dotenv.load_dotenv()
except Exception:
    pass

# Autogen / MCP imports - Society of Mind pattern
from autogen_ext.models.openai import OpenAIChatCompletionClient
from autogen_ext.tools.mcp import McpWorkbench
from autogen_ext.tools.mcp import StdioServerParams, create_mcp_server_session, mcp_server_tools
from autogen_agentchat.agents import AssistantAgent, SocietyOfMindAgent
from autogen_agentchat.teams import RoundRobinGroupChat
from autogen_agentchat.conditions import TextMentionTermination
from autogen_core.tools import ImageResultContent

# Event broadcasting for live GUI updates
import sys
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'shared'))
from event_broadcaster import EventServer, start_event_server

# Import shared model initialization
from model_init import init_model_client as shared_init_model_client

# Optional: rich console for nicer logs
try:
    from rich.console import Console
    from rich.traceback import install
    install()
    console = Console()
except Exception:
    console = None

# ========== Constants ==========
DEFAULT_SYSTEM_PROMPT = """{sys_match.group(1)}"""

DEFAULT_TASK_PROMPT = """{task_match.group(1)}"""

# ========== Society of Mind Prompts ==========
def load_prompt_from_module(module_name: str, default: str) -> str:
    """Load prompt from a Python module's PROMPT variable."""
    try:
        import importlib.util
        module_path = os.path.join(BASE_DIR, f"{module_name}.py")
        if os.path.exists(module_path):
            spec = importlib.util.spec_from_file_location(module_name, module_path)
            if spec and spec.loader:
                module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(module)
                if hasattr(module, 'PROMPT'):
                    return module.PROMPT
        return default
    except Exception as e:
        print(f"Warning: Failed to load prompt from {module_name}: {e}")
        return default

DEFAULT_GITHUB_OPERATOR_PROMPT = """ROLE: Filesystem Operator
Complete Filesystem-related tasks using available Filesystem MCP tools.
Signal completion with: READY_FOR_VALIDATION
"""

DEFAULT_QA_VALIDATOR_PROMPT = """ROLE: QA Validator
Verify Filesystem task completion.
Respond with 'APPROVE' if correct, or list issues if incomplete.
"""

# ========== File helpers ==========
BASE_DIR = os.path.dirname(__file__)
SERVERS_DIR = os.path.dirname(BASE_DIR)  # .../servers
PLUGINS_DIR = os.path.dirname(SERVERS_DIR)  # .../MCP PLUGINS
MODELS_DIR = os.path.join(PLUGINS_DIR, "models")

SYSTEM_PROMPT_PATH = os.path.join(BASE_DIR, "system_prompt.txt")
TASK_PROMPT_PATH = os.path.join(BASE_DIR, "task_prompt.txt")
SERVERS_CONFIG_PATH = os.path.join(SERVERS_DIR, "servers.json")
MODEL_CONFIG_PATH = os.path.join(MODELS_DIR, "model.json")
SECRETS_PATH = os.path.join(SERVERS_DIR, "secrets.json")

# Ensure directory structure exists
os.makedirs(BASE_DIR, exist_ok=True)


def _read_text_file(path: str, default: str) -> str:
    """Read a text file, return default if missing."""
    if not os.path.isfile(path):
        return default
    try:
        with open(path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception:
        return default


def _write_text_file(path: str, content: str) -> None:
    """Write content to a text file."""
    try:
        with open(path, 'w', encoding='utf-8') as f:
            f.write(content)
    except Exception:
        pass


def get_system_prompt() -> str:
    """Get system prompt for Filesystem agent."""
    prompt = _read_text_file(SYSTEM_PROMPT_PATH, DEFAULT_SYSTEM_PROMPT)
    if not os.path.isfile(SYSTEM_PROMPT_PATH):
        _write_text_file(SYSTEM_PROMPT_PATH, DEFAULT_SYSTEM_PROMPT)
    return prompt


def get_task_prompt() -> str:
    """Get task prompt for Filesystem operations."""
    prompt = _read_text_file(TASK_PROMPT_PATH, DEFAULT_TASK_PROMPT)
    if not os.path.isfile(TASK_PROMPT_PATH):
        _write_text_file(TASK_PROMPT_PATH, DEFAULT_TASK_PROMPT)
    return prompt


def load_model_config() -> Dict[str, Any]:
    """Load model configuration from models/model.json."""
    if not os.path.isfile(MODEL_CONFIG_PATH):
        return {
            "model": os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
            "base_url": os.getenv("OPENAI_BASE_URL"),
            "api_key_env": "OPENAI_API_KEY"
        }
    try:
        with open(MODEL_CONFIG_PATH, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception:
        return {
            "model": "gpt-4o-mini",
            "base_url": None,
            "api_key_env": "OPENAI_API_KEY"
        }


def load_servers_config() -> List[Dict[str, Any]]:
    """Load servers configuration from servers.json."""
    if not os.path.isfile(SERVERS_CONFIG_PATH):
        return []
    try:
        with open(SERVERS_CONFIG_PATH, 'r', encoding='utf-8') as f:
            data = json.load(f)
            return data.get('servers', [])
    except Exception:
        return []


def load_secrets() -> Dict[str, Any]:
    """Load secrets from secrets.json."""
    if not os.path.isfile(SECRETS_PATH):
        return {}
    try:
        with open(SECRETS_PATH, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception:
        return {}


def init_model_client(task: str = "") -> OpenAIChatCompletionClient:
    """Initialize OpenAI chat completion client with intelligent routing.

    Args:
        task: Task description (optional, used for model selection)

    Returns:
        OpenAIChatCompletionClient configured with appropriate model
    """
    # Use shared model initialization utility
    return shared_init_model_client("filesystem", task)


# ========== Filesystem Agent ==========
class FilesystemAgent:
    """AutoGen agent for Filesystem MCP server operations."""

    def __init__(self, model_client: Optional[OpenAIChatCompletionClient] = None):
        self.model_client = model_client or init_model_client()
        self.workbench: Optional[McpWorkbench] = None
        self.assistant: Optional[AssistantAgent] = None
        self._initialized = False
        self.event_server: Optional[EventServer] = None
        self.event_http_server = None
        self.event_port: Optional[int] = None

    async def initialize(self) -> None:
        """Initialize the Filesystem MCP workbench and agent."""
        if self._initialized:
            return

        # Load server configuration
        servers = load_servers_config()
        github_config = None
        for srv in servers:
            if srv.get("name") == "filesystem" and srv.get("active"):
                github_config = srv
                break

        if not github_config:
            raise ValueError("Filesystem MCP server not found or not active in servers.json")

        # Load secrets
        secrets = load_secrets()
        github_secrets = secrets.get("filesystem", {})

        # Prepare environment variables
        env = os.environ.copy()

        # First, try to load from secrets.json
        for key, val in github_secrets.items():
            if val:  # Only set if value is not empty
                env[key] = val

        # Then, override with environment variables if present
        env_vars = github_config.get("env_vars", {})
        for key, val in env_vars.items():
            if isinstance(val, str) and val.startswith("env:"):
                env_key = val[4:]
                env_val = os.getenv(env_key)
                if env_val:
                    env[key] = env_val

        # Create MCP server session
        server_params = StdioServerParams(
            command=github_config["command"],
            args=github_config["args"],
            env=env
        )

        # Store server params for context manager usage
        self.server_params = server_params

        # Initialize event server for live GUI updates
        self.event_server = EventServer()
        httpd, thread, host, port = start_event_server(self.event_server, host="127.0.0.1", port=0)
        self.event_http_server = httpd
        self.event_port = port

        # Write port info for GUI proxy discovery
        port_file = os.path.join(BASE_DIR, ".event_port")
        with open(port_file, 'w') as f:
            f.write(str(port))

        self._initialized = True
        if console:
            console.print(f"[green]Filesystem Agent initialized with Society of Mind (Operator + QA Validator)[/green]")
            console.print(f"[blue]Event server running on http://127.0.0.1:{port}/events[/blue]")

    async def run_task(self, task: str, correlation_id: str = None) -> Dict[str, Any]:
        """Execute a Filesystem task and return results."""
        if not self._initialized:
            await self.initialize()

        # Reinitialize model client with task-aware model selection
        # This allows intelligent routing based on task complexity
        task_aware_client = init_model_client(task)

        task_prompt = get_task_prompt()
        full_prompt = f"{task_prompt}\n\nTask: {task}"

        try:
            # Use context manager for MCP workbench
            async with McpWorkbench(self.server_params) as mcp:
                # Load Society of Mind prompts
                operator_prompt = load_prompt_from_module("filesystem_operator_prompt", DEFAULT_GITHUB_OPERATOR_PROMPT)
                qa_prompt = load_prompt_from_module("qa_validator_prompt", DEFAULT_QA_VALIDATOR_PROMPT)

                # Create Filesystem Operator agent (with workbench)
                github_operator = AssistantAgent(
                    "FilesystemOperator",
                    model_client=task_aware_client,
                    workbench=mcp,
                    system_message=operator_prompt
                )

                # Create QA Validator agent (no tools, pure validation)
                qa_validator = AssistantAgent(
                    "QAValidator",
                    model_client=task_aware_client,
                    system_message=qa_prompt
                )

                # Inner team termination: wait for "APPROVE" from QA Validator
                inner_termination = TextMentionTermination("APPROVE")
                inner_team = RoundRobinGroupChat(
                    [github_operator, qa_validator],
                    termination_condition=inner_termination,
                    max_turns=30  # Safety limit
                )

                # Society of Mind wrapper
                som_agent = SocietyOfMindAgent(
                    "github_society_of_mind",
                    team=inner_team,
                    model_client=task_aware_client
                )

                # Outer team (just the SoM agent)
                team = RoundRobinGroupChat([som_agent], max_turns=1)

                # Run the agent and stream messages
                print(f"\n{'='*60}")
                print(f"🎭 Society of Mind: Filesystem Operator + QA Validator")
                print(f"{'='*60}\n")

                # Broadcast session start
                if self.event_server:
                    self.event_server.broadcast("session.status", {
                        "status": "started",
                        "tool": "filesystem",
                        "task": task,
                        "correlation_id": correlation_id
                    })

                messages = []
                async for message in team.run_stream(task=full_prompt):
                    messages.append(message)

                    # Extract and print agent messages for live viewing
                    if hasattr(message, 'source') and hasattr(message, 'content'):
                        source = message.source
                        content = str(message.content)

                        # Pretty print agent dialogue
                        if source == "FilesystemOperator":
                            print(f"\n🔧 FilesystemOperator:")
                            print(f"   {content[:500]}{'...' if len(content) > 500 else ''}")
                            # Broadcast to GUI
                            if self.event_server:
                                self.event_server.broadcast("agent.message", {
                                    "agent": "FilesystemOperator",
                                    "role": "operator",
                                    "content": content,
                                    "icon": "🔧"
                                })
                        elif source == "QAValidator":
                            print(f"\n✓ QAValidator:")
                            print(f"   {content[:500]}{'...' if len(content) > 500 else ''}")
                            # Broadcast to GUI
                            if self.event_server:
                                self.event_server.broadcast("agent.message", {
                                    "agent": "QAValidator",
                                    "role": "validator",
                                    "content": content,
                                    "icon": "✓"
                                })

                        # Check for tool calls
                        if hasattr(message, 'content') and isinstance(message.content, list):
                            for item in message.content:
                                if hasattr(item, 'name'):  # Tool call
                                    print(f"   🛠️  Tool: {item.name}")
                                    # Broadcast to GUI
                                    if self.event_server:
                                        self.event_server.broadcast("tool.call", {
                                            "tool": item.name,
                                            "icon": "🛠️"
                                        })

                print(f"\n{'='*60}")
                print(f"✅ Task completed")
                print(f"{'='*60}\n")

                # Broadcast session completion
                if self.event_server:
                    self.event_server.broadcast("session.status", {
                        "status": "completed",
                        "message_count": len(messages)
                    })

                # Extract outputs
                result_text = "\n".join([str(m) for m in messages[-3:]])  # Last few messages
                outputs = {
                    "status": "completed",
                    "result": result_text,
                    "correlation_id": correlation_id,
                    "message_count": len(messages)
                }

                return outputs
        except Exception as e:
            # Broadcast error
            if self.event_server:
                self.event_server.broadcast("session.status", {
                    "status": "error",
                    "error": str(e)
                })
            return {
                "status": "error",
                "error": str(e),
                "correlation_id": correlation_id
            }

    async def shutdown(self) -> None:
        """Shutdown the workbench and cleanup."""
        # Shutdown event server
        if self.event_http_server:
            self.event_http_server.shutdown()
            self.event_http_server = None
        # No cleanup needed for workbench - context manager handles it
        self._initialized = False


# ========== Main Entry Point ==========
async def main():
    """Example usage of Filesystem agent."""
    agent = FilesystemAgent()
    await agent.initialize()

    # Example task
    task = "List the latest issues in the microsoft/vscode repository"
    result = await agent.run_task(task)

    print(json.dumps(result, indent=2))

    await agent.shutdown()


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="Filesystem MCP Agent with Society of Mind")
    parser.add_argument("--task", help="Task for the agent to execute")
    parser.add_argument("--session-id", dest="session_id", help="Session identifier")
    args = parser.parse_args()

    # If task is provided via CLI, run it
    if args.task:
        async def run_cli():
            agent = FilesystemAgent()
            await agent.initialize()
            print(f"Society of Mind: Filesystem Operator + QA Validator")
            print(f"Starting task: {args.task}")
            result = await agent.run_task(args.task, correlation_id=args.session_id)
            print(json.dumps(result, indent=2))
            await agent.shutdown()
        asyncio.run(run_cli())
    else:
        # Fallback to example
        asyncio.run(main())