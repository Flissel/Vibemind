# Sakana Desktop Assistant Configuration

# LLM Settings
llm_provider: "local"
model_name: "llama-3.2-3b"
temperature: 0.7
max_tokens: 2048

# Memory Settings
max_short_term_memory: 100
max_long_term_memory: 10000

# Learning Settings
learning_rate: 0.01
evolution_generations: 10
population_size: 20
mutation_rate: 0.1

# Security Settings
sandbox_enabled: true
max_execution_time: 30

# UI Settings
enable_gui: false
enable_voice: false